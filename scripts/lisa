#!/usr/bin/env python
"""
function for motif delta regulatory potential
"""
from functools import reduce
import yaml

import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.patches as p
import seaborn as sns

import numpy as np
import pandas as pd

import math
import sys
import os
import argparse
import pickle
import glob

from scipy.spatial.distance import squareform
from scipy.cluster.hierarchy import linkage, to_tree

from marge2_conf import Config
import h5py
from marge2 import (get_clean_path,
                    HDF,
                    Annotation, Model, annotate,
                    log_transform, chrom_bin_boundary, load_chip_meta, load_motif_meta,
                    ks_test_df, ks_test,
                    site_binarize,
                    add_node
                    )
from pkg_resources import resource_filename
from string import Template
import json

def process_args():
    parser = argparse.ArgumentParser()

   # specific mode option
    subparsers = parser.add_subparsers(dest="sub", help="sub command")

    fastq = subparsers.add_parser("fastq", help="raw data processing only support for H3K27ac now, LISA with pipeline to process raw fastq: 1.mapping; 2. generate bigWiggle; 3. generate new HDF5 for RP and 1kb Read Count; 4. run LISA model to regress and rank TF module")
    fastq.add_argument('--fastq', required=True, help='input fastq file. need to fill in the conf for bwa genome index. If multiple fastq, separated by comma, e.g. 1.fastq,2.fastq')
    fastq.add_argument('--gene', required=True, help='gene list text file, one refseq or symbol per line')

    logit = subparsers.add_parser("logit", help="logistic regression specific option")
    logit.add_argument('--gene', required=True, help='gene list text file, one refseq or symbol per line')
    logit.add_argument('--cluster', default=False, action='store_true', help='cluster analysis of motif')

    linear = subparsers.add_parser("linear", help="linear regression specific option")
    linear.add_argument('--foldchange', required=True, help='differential gene fold change, column 1: gene name or refseq, column 2: fold change value')
 
    # common options
    for p in [logit, linear, fastq]:
        p.add_argument('--DNase', default=False, action='store_true', help='use l1 selected dnase samples peak to filter tfbs or not, should not be used with --DNase2')
        p.add_argument('--DNase2', default=False, action='store_true', help='use union DHS to filter tfbs or not, under testing, should not be used with --DNase, get from scripts/uDHS_overlap_100bp.sh')
        p.add_argument('--config', help='lisa configuration file', default=resource_filename("m2", 'lisa.conf'))
        p.add_argument('--tf', required=True, help='TF peak BED overlapped with 100bp window position index stored as numpy binary array, referred to scripts/fetch__tf_binarray.sh')
        p.add_argument('--bl', default=1000, help='bin size')
        p.add_argument('--fast', default=True, action='store_false', help='use batch mode for fast matrix operation')
        p.add_argument('--histone', default='H3K27ac,DNase,H3K4me1,H3K4me3,H3K4me2,H3K27me3,H3K36me3,H3K9me3,ATAC-seq,H3K9ac', help='default: H3K27ac,DNase,H3K4me1,H3K4me3,H3K4me2,H3K27me3,H3K36me3,H3K9me3,ATAC-seq,H3K9ac. specify which histone marks to use, e.g.,H3K27ac,DNase,ATAC-seq,H3K4me1; with lisa fastq mode, this should be the same as the input_fastq_folder, see README.md')
        p.add_argument('--additional_h5', default=None, help='the path for additional hdf5 generated by lisa fastq, this is useful when need to combine in-house epigenomics dataset; e.g.: name_H3K27ac.h5. One additional hdf5 for a time. name is --name')
        p.add_argument('--name', default='test', help='this should be as unique as possible, output name prefix')
        p.add_argument('--species', default='hg38', choices=['hg38', 'mm10'], help='which species')
        p.add_argument('-O', required=True, help='output final html js json directory')
        p.add_argument('--top', default=10, type=int, help='arbitrary top samples to select, default: 12 ')
        p.add_argument('--motif_cutoff', default='99', type=str, help='whole genome 100bp window motif cutoff, e.g. 97,99, default only: 99, means 99 percentile cutoff, only 97,98,99 are available')
        p.add_argument('--penalty', default='l1', type=str, choices=['l1', 'l2'], help='penalty, default: l1. l2 may be better, is still under testing.')
        p.add_argument('--ks_top', default=100, type=int, help='top TFs based on ks.test of in-silico deletions.')
        p.add_argument('--evaluate_top', default=False,  action='store_true', help='top motif/chip list ranked by p-value, and arbitrary top samples to select')
        p.add_argument('--EXPANDDNase', default=None, help='additional DNase-seq peak regions for filtering motif or chip-seq peak, use either with --DNase or --DNase2')

    args = parser.parse_args()
    return args

def merge_marks(all_jsons, name, outdir, args):
    """ output into public_html folder for browsing
    """ 
    os.system('mkdir -p %s' % outdir)
    m2t = resource_filename("m2", "template")
    with open(resource_filename("m2", "template/index.html")) as t:
        t = Template(t.read())

    if args.DNase:
        dnase = '_dnase'
    else:
        if args.DNase2:
            dnase = '_dnase'
        else:
            dnase = ''

    index = t.substitute({'study_name': name, 'dnase': dnase})
    with open(os.path.join(outdir, 'index.html'), 'w') as outf:
        outf.write(index)
    os.system('cp {0}/*css {0}/*js {1} {2}'.format(m2t, ' '.join(all_jsons), outdir))

def linear_mode(args):
    config = Config(args.config, args.species)

    marks = args.histone.split(",")
    jsons = [] # package all jsons into -O output directory
    gene = get_clean_path(args.foldchange)
    fold = pd.read_table(gene, header=None, index_col=0)
    h5 = HDF(config)

    # ann = Annotation(config, fold, None, args.bl)

    for individual_mark in marks[:1]:
        # get configuration for the data
        label_output = "_%s_linear" % individual_mark
    
        if (not (os.path.exists("%s.fs%s" % (gene, label_output)) and os.path.getsize("%s.fs%s" % (gene, label_output))>0)): 
            # X : RP, Y: Differential gene set
            ids, first_ref, sym, X, Y = h5.get_rp_XY_withfold(fold, individual_mark, other_h5=None)
            X = log_transform(X)

            model = Model(X, Y, ids, sym, first_ref, top=args.top, mode=args.sub)
            model.linear_fit()
            # with open("%s.fs%s" % (gene, label_output), 'wb') as fp:
            #     pickle.dump(model, fp)
        #     # add dnase information
        #     if args.DNase:
        #         ids, first_ref, sym, X, Y = h5.get_rp_XY(ann.get_gene_set(), None, other_h5 = None, DNase=args.DNase)
        #         X = log_transform(X)
        #         dnase_model = Model(X, Y, ids, sym, first_ref, args.top)
        #         dnase_most_info_id = dnase_model.get_dnase_most_info_id()
        #         with open("%s.fs%s.dnase" % (gene, label_output), 'wb') as fp:
        #             pickle.dump(dnase_most_info_id, fp)
        #         label_output += '_dnase'
        #     else:
        #         label_output += '_nodnase'
        #         dnase = False
        # else:
        #     with open("%s.fs%s" % (gene, label_output), 'rb') as fp:
        #         model = pickle.load(fp)
        #     if args.DNase: # pickle dnase id only
        #         with open("%s.fs%s.dnase" % (gene, label_output), 'rb') as fp:
        #             dnase_most_info_id = pickle.load(fp)
        #         label_output += '_dnase'
        #     else:
        #         label_output += '_nodnase'
        #         dnase = False

        histone_meta = pd.read_csv(config.get_meta, index_col=0, encoding='ISO-8859-1')
        clean_meta = histone_meta.apply(annotate, axis=1)
        f = open(individual_mark + "_" + args.name + ".coef", 'w')
        f.write("name\tvalue\n")
        for i,j in zip(model.sid, model.coefs):
            f.write("%s_%s\t%s\n" %(i, clean_meta.loc[int(i)], j))
        f.close()

def main():
    args = process_args()
    if args.sub == "linear":
        linear_mode(args)
    if args.sub == "logit":
        logit_mode(args)
    if args.sub == "fastq":
        from_fastq(args)

def logit_mode(args):

    print("%s feature..." % args.top)
    marks = args.histone.split(",")
    print("all marks: %s " % '\t'.join(marks))
    jsons = [] # package all jsons into -O output directory

    other_h5 = args.additional_h5 # merged h5 from different factors, generated from fastq subparsers

    for individual_mark in marks:
        # get configuration for the data
        gene = get_clean_path(args.gene)
        config = Config(args.config, args.species)
        ann = Annotation(config, gene, None, args.bl)
        h5 = HDF(config)
        label_output = "_%s_withpromoter" % individual_mark
        if (not (os.path.exists("%s.fs%s" % (gene, label_output)) and os.path.getsize("%s.fs%s" % (gene, label_output))>0)):
            # X : RP, Y: Differential gene set
            ids, first_ref, sym, X, X_unique, Y, refs = h5.get_rp_XY(ann.get_gene_set(), individual_mark, other_h5)
            X = log_transform(X)
            X_unique = log_transform(X_unique)
            model = Model(X, X_unique, Y, refs, ids, sym, first_ref, args.top, penalty=args.penalty)
            with open("%s.fs%s" % (gene, label_output), 'wb') as fp:
                model.fit()
                pickle.dump(model, fp)
        else:
            with open("%s.fs%s" % (gene, label_output), 'rb') as fp:
                model = pickle.load(fp)

        # add dnase information
        if args.DNase:
            if (not (os.path.exists("%s.fs%s.dnase" % (gene, label_output)) and os.path.getsize("%s.fs%s.dnase" % (gene, label_output))> 0)):
                # in-house HDF5 only support H3K27ac now!!!
                # turn other_h5 to None here
                ids, first_ref, sym, X, X_unique, Y, refs = h5.get_rp_XY(ann.get_gene_set(), None, other_h5=None, DNase=args.DNase)
                X = log_transform(X)
                X_unique = log_transform(X_unique)
                dnase_model = Model(X, X_unique, Y, refs, ids, sym, first_ref, args.top, penalty=args.penalty)
                dnase_most_info_id = dnase_model.get_dnase_most_info_id()
                with open("%s.fs%s.dnase" % (gene, label_output), 'wb') as fp:
                    pickle.dump(dnase_most_info_id, fp)
                label_output += '_dnase'
                dnase = True
            else:
                with open("%s.fs%s.dnase" % (gene, label_output), 'rb') as fp:
                    dnase_most_info_id = pickle.load(fp)
                label_output += '_dnase'
                dnase = True
        else:
            if args.DNase2: # for union DHS filter motif or chip-seq peak
                label_output += '_dnase' 
                dnase = True
            else:
                label_output += '_nodnase'
                dnase = False

        marge_rp_file = open("%s.%s.margerp" % (individual_mark, args.name), "w")
        for v, k in model.marge_rp_dict.items():
            marge_rp_file.write("%s\t%s\n" %(k, v))
        marge_rp_file.close()
        d3json = {"performance":model.performance,
                  "tpr": list(model.tpr), "fpr": list(model.fpr)}
        with open(individual_mark + "_" + args.name + "_performance.json", "w") as out_js:
            json.dump(d3json, out_js, sort_keys=True, indent=4)
        jsons.append(individual_mark + "_" + args.name + "_performance.json")

        histone_meta = pd.read_csv(config.get_meta, index_col=0, encoding='ISO-8859-1')
        clean_meta = histone_meta.apply(annotate, axis=1)
        f = open(individual_mark + "_" + args.name + ".coef", 'w')
        f.write("name\tvalue\n")
        for i,j in zip(model.sid, model.coefs):
            try:
                f.write("%s_%s\t%s\n" %(i, clean_meta.loc[int(i)], j))
            except:
                f.write("%s\t%s\n" %(i, j))
        f.close()
        jsons.append(individual_mark + "_" + args.name + ".coef")
    
        # 100bp windows are not 10 times of 1000bp windows
        # use an numpy array to assist mapping 100bp to 1kb windows
        window_map = np.load(config.genome_window_map) # 0-based
        if args.DNase: # DNase summits or not in 100bp bins
            dnase_index = []
            with h5py.File(config.get_dnase_bin) as dnase:
                for did in dnase_most_info_id[:5]: # use the top 5 dnase ids with absolute coef
                    try:
                        #print('dnase %s...' % did)
                        dnase_index.append(dnase['dnase_' + did][:]) # 1-based
                    except ValueError:
                        print('dnase error... %s' % did)
                        continue # there is some dnase sample with only one summit, exclude
    
            dnase_index = reduce(np.union1d, dnase_index)
            dnase = dnase_index-1 # 0-based np.int32 index, 100bp window based bin index, great!!!
        else:
            if args.DNase2:
                dnase = np.load(config.get_udhs)-1 # 1-based uDHS in 100bp window index, -1
            else:
                dnase = False

        if args.EXPANDDNase != None:
            if os.path.exists(args.EXPANDDNase):
                dnase_expand = site_binarize(config, args.EXPANDDNase) # 0-based
                if args.DNase or args.DNase2:
                    dnase = np.union1d(dnase, dnase_expand)
                else:
                    dnase = np.array(dnase_expand)
                    #raise # EXPANDDNase must be used with DNase or DNase2 option

        # to be consistent with motif 100bp resolution analysis
        # use 100bp for chip-seq peak as well
        if args.tf == 'no':
            count_Y = None; count_Y_test = None
        else:
            count_Y_index = np.load(args.tf) # 1-based, tf chip-seq summit index in 100bp windows, numpy arrary
            count_Y = count_Y_index-1 # 0-based np.int32 index for 100bp window

            count_Y_test = np.zeros(window_map[-1]+1, dtype=np.int32) # for test semi-supervised TF binding only at 1kb window
            count_Y_test[window_map[count_Y]] = 1 # map 100bp to 1000bp

        # load epigenomics read count of 1kb window and test the model
        test = model.test(individual_mark, h5, count_Y_test, other_h5)
        f = open("%s.fs%s.top%s" % (gene, label_output, args.top), 'w+')
        if isinstance(test, str):
            f.write(test)
        else:
            f.write("%f\t%f" % (test[0],test[1]))
        f.close()

        if args.evaluate_top: # hidden options for evaluating selected sample size effect
            # only evaluation, then quit
            sys.exit(0)

        # load chromatin bin boundary
        chrom_bin = chrom_bin_boundary(config)
        cutoffs = list(map(int, args.motif_cutoff.split(',')))
        if args.cluster:
            ann = Annotation(config, gene, None, args.bl)
            motif_h5s = [] 
            for cut in cutoffs:
               # motif_h5s.append(config.get_motif_1kb(cut)) # bool operation not fast
                motif_h5s.append(config.get_motif_index(cut)) # use index instead 
            model.cluster_motif_score(motif_h5s, cutoffs, "%s_%s" %(args.name, individual_mark), ann, chrom_bin, count_Y_test, config, window_map)
            continue ## to finish all the marks
            #sys.exit(0)
    
        tfchip = {}
        load_chip_meta(config, tfchip)
    
        diff = np.sum(model.Y)
        tf = args.name
    
        motif_h5s = []
        for cut in cutoffs:
            motif_h5s.append(config.get_motif_index(cut))
        ## obsoleted!! use 1kb windows motif 1-0 matrix, use above instead
        #for cut in cutoffs:
        #    motif_h5s.append(config.get_motif_1kb(cut))
    
        motif_map = load_motif_meta(config)
        motif_name_dict = {}
        motif_family_dict = {}
        for i, s, d in zip(motif_map.id, motif_map.symbol, motif_map.dbd):
            motif_name_dict[i] = s
            motif_family_dict[i] = d
    
        def label_tree( n ):
            if len(n["children"]) == 0: # leaf node
                leafNames = [ id2name[n["node_id"]] ]
                n["name"] = motif_name_dict[leafNames[0]]
            else: # internal node, use motif family name to show the colors in d3js
                leafNames = list(reduce(lambda x,y: x+label_tree(y), n["children"], [])) # return a list of flattened leaf node
                leafFamily = list(map(lambda x: motif_family_dict[x], leafNames))
                # use the largest portion of the motif family
                leafFamily = np.unique(leafFamily, return_counts = True)
                maxFams, = np.where(leafFamily[1] == np.max(leafFamily[1]))
                maxFams = leafFamily[0][maxFams]
                n["name"] = maxFams[0]
            # del n["node_id"]
            return leafNames # leaf node return the pwm id
    
        def label_leaf_node_stat( n ):
            if len(n["children"]) == 0:
                r = motif_stat[id2name[n["node_id"]]][1]
                if np.isnan(r):
                    n["margerp"] = 0 ## NaN->0, str(r)
                else:
                    n["margerp"] = r
                n["p"] = motif_stat[id2name[n["node_id"]]][0]
            else:
                #map(label_leaf_node_stat, n["children"])
                list(map(label_leaf_node_stat, n["children"])) ## Python3 map behavior is weird
            del n["node_id"]
    
        def chip_label_tree( n ):
            if len(n["children"]) == 0: # leaf node
                leafNames = [ id2name[n["node_id"]] ]
                n["name"] = tfchip[leafNames[0]]
            else: # internal node, use motif family name to show the colors in d3js
                leafNames = list(reduce(lambda x,y: x+chip_label_tree(y), n["children"], [])) # return a list of flattened leaf node
            return leafNames # leaf node return the pwm id
    
        def chip_label_leaf_node_stat( n ):
            if len(n["children"]) == 0:
                r = chip_stat[id2name[n["node_id"]]][1]
                if np.isnan(r):
                    n["beta"] = 0 ## NA->0, str(r)
                else:
                    n["beta"] = r
                n["p"] = chip_stat[id2name[n["node_id"]]][0]
            else:
                #map(chip_label_leaf_node_stat, n["children"])
                list(map(chip_label_leaf_node_stat, n["children"]))
            del n["node_id"]
    
        # TF ChIP-seq from Cistrome, this is 1-based index h5
        # Chip-seq peak delta rp matrix with unique diff and background gene 
        # e.g. PPARG_delta_batch_H3K4me2_withpromoter_dnase_cistrome_dc.txt
        out_delta2 = '%s_delta_batch%s_cistrome_dc.txt' % (tf, label_output)
        if not (os.path.exists(out_delta2) and os.path.getsize(out_delta2) > 0):
            fout2 = open(out_delta2, 'w')
            out_diff = []
            for index, ref in enumerate(model.refseqs):
                if index < diff:
                    out_diff.append('1')
                else:
                    out_diff.append('0')
            fout2.write("%s\n"%'\t'.join(out_diff))
            fout2.write("%s\n"%'\t'.join(list(model.refseqs)))
    
            ann = Annotation(config, gene, None, args.bl)
            batch_motif = model.get_delta_rp_openmp(count_Y, config.tf_chipseq, chrom_bin, ann, cutoff=cut, DNase=dnase, window_map=window_map, dc_chip=True)
            for (batch_ids, batch_tfs, delta) in batch_motif:
                for i, t, d in zip(batch_ids, batch_tfs, delta):
                    try: ## Python3 str or bytes from hdf5, sometimes change between...
                        fout2.write("%s\t%s\n" % (i.decode('utf-8').replace("tf_", ""), '\t'.join(map(str, list(d)))))
                    except:
                        fout2.write("%s\t%s\n" % (i.replace("tf_", ""), '\t'.join(map(str, list(d)))))
            fout2.close()
    
        ks_test_df(out_delta2)
        s = pd.read_csv("%s.ks" % out_delta2, header=None, index_col=0, encoding='ISO-8859-1')
        ss = s.sort_values([1], ascending=True).head(args.ks_top)
    
        with h5py.File(config.get_beta) as store:
            beta_ids = list(map(lambda x: x.decode('utf-8').replace("_peaks_5fold", ""), list(store['IDs'][...])))
            beta = pd.DataFrame(store['RP'][...], columns=beta_ids, index=store['RefSeq'][...]) # TODO, use new hdf5 instead of beta hdf5

        ss_ids = list(map(lambda x: x.replace("_peaks_5fold", ""), ss.index.astype(np.str).values))
        ss.index = ss_ids
        bmat = beta.loc[:, ss_ids] # dc id selected beta matrix
        diff_gene = []
        cont_gene = []
        for index, ref in enumerate(model.refseqs):
            if index < diff:
                diff_gene.append(ref)
            else:
                cont_gene.append(ref)

        # BETA use the same differential and background gene to KS test
        bmat_index = bmat.index.astype(np.str).values
        bmat_index = list(map(lambda x: x.split(":")[-2], list(bmat_index)))

        diff_beta = np.in1d(bmat_index, diff_gene)
        cont_beta = np.in1d(bmat_index, cont_gene)

        beta_ks = bmat.apply(lambda x: ks_test(x[cont_beta], x[diff_beta])) # non vs diff
        beta_ks.to_csv(out_delta2 + '.beta')
    
        beta_ks = pd.read_csv(out_delta2 + '.beta', header=None, index_col=0, encoding='ISO-8859-1')
        beta_ks.index = beta_ks.index.astype(np.str)
        ss = pd.merge(ss, beta_ks, left_index=True, right_index=True, how='inner')
        ss.columns = ["p", "beta"]
        ss.to_csv("%s.dc.combined" % out_delta2)
    
        labels = list(bmat.columns)
        id2name = dict(zip(range(len(labels)), labels))
    
        bdist = 1 - bmat.corr(method="spearman")

        ## NOTE::: turn off symmetric check: weird, pandas return correlation matrix slightlly not symmetric
        sq = squareform(bdist, checks=False)
        try:  
            # the distance matrix in some cases has infinite values which raises ValueError
            # such as GR...
            clusters = linkage(sq, method="single")
        except ValueError:
            # due to https://github.com/scipy/scipy/commit/cf31ab151dce04143082ee45e39f26198cda26c8
            sq[np.isinf(sq)] = 10000 # give infinite values a large number, 10000 here
            sq[np.isnan(sq)] = 0 # give nan values 0 
            clusters = linkage(sq, method="single")

        dendro_tree = to_tree(clusters, rd=False) # root node
        d3js = dict(children = [], name = "Root", length = 0)
        add_node(dendro_tree, d3js)
    
        # get statistics dict for labeling node
        chip_stat = {}
        for p, i, b in zip(ss.p, ss.index, ss.beta):
            chip_stat[i] = [p, b]
    
        chip_label_tree(d3js["children"][0])

        print(list(chip_stat.keys())[:5])
        chip_label_leaf_node_stat(d3js["children"][0])
        with open("%s.json" % out_delta2.replace(".txt", ""), "w") as out_js:
            json.dump(d3js, out_js, sort_keys=True, indent=4)
        jsons.append("%s.json" % out_delta2.replace(".txt", ""))
    
        # a series of cutoffs for Cistrome motif sites
        for cut, motif_h5 in zip(cutoffs, motif_h5s):
            # gene labeled with the first refseq id
            # unique background and differential genes
            # e.g. PPARG_delta_batch_H3K4me3_withpromoter_dnase_99.txt
            # e.g. PPARG_delta_batch_H3K4me3_withpromoter_nodnase_99.txt
            out_delta = '%s_delta_batch%s_%s.txt' % (tf, label_output, str(cut))
            if not (os.path.exists(out_delta) and os.path.getsize(out_delta) > 0):
                fout = open(out_delta, 'w')
                # output the column header
                out_diff = []
                for index, ref in enumerate(model.refseqs):
                    if index < diff:
                        out_diff.append('1')
                    else:
                        out_diff.append('0')
                fout.write("%s\n" % '\t'.join(out_diff))
                fout.write("%s\n" % '\t'.join(list(model.refseqs)))
                ann = Annotation(config, gene, None, args.bl)
                ##batch_motif = model.get_mini_batch_delta_rp(count_Y, motif_h5, chrom_bin, ann, cutoff=cut, DNase=dnase, window_map=window_map, theano_mode=True)
                batch_motif = model.get_delta_rp_openmp(count_Y, motif_h5, chrom_bin, ann, cutoff=cut, DNase=dnase, window_map=window_map, dc_chip=False)
                for (batch_ids, batch_tfs, delta) in batch_motif:
                    for i, t, d in zip(batch_ids, batch_tfs, delta): # i: id, t: name, d: delta numpy array
                        fout.write("%s\t%s\n" % (i.decode('utf-8'), '\t'.join(map(str, list(d)))))
                fout.close()

        sim = pd.read_table(config.get_motif_sim)
        distMat = 1 - sim
        for cut, motif_h5 in zip(cutoffs, motif_h5s):
            out_delta = '%s_delta_batch%s_%s.txt' % (tf, label_output, str(cut))
            ks_test_df(out_delta)
            s = pd.read_csv("%s.ks" % out_delta, header=None, encoding='ISO-8859-1')
            s = pd.merge(s, motif_map, left_on=0, right_on='id', how='inner').iloc[:,[2,3,4,5,6,1]]
            ss = s.sort_values([1], ascending=True).head(args.ks_top)
            def fetch_rp(rp, x):
                if pd.isnull(x[4]):
                    return 0
                for i in x[4].split("|"):
                    if rp.get(i, "") != "":
                        return rp.get(i, 0)
                return 0
            # if any of the refseq is in marge_rp_dict return the MARGE predicted RP
            ss = pd.concat([ss, ss.apply(lambda x: fetch_rp(model.marge_rp_dict, x), axis=1)], axis=1) # use 0 instead of np.nan
            ss.columns = ["id", "source", "family", "symbol", "refseq", "p", "margerp"]
            ss.to_csv("%s.combined" % out_delta)

            # get statistics dict for labeling node
            motif_stat = {}
            for p, m, i in zip(ss.p, ss.margerp, ss.id):
                motif_stat[i] = [p, m]
            motif_filter = distMat.ix[ss.id.values, ss.id.values]
            labels = list(motif_filter.columns)
            id2name = dict(zip(range(len(labels)), labels))

            sq = squareform(motif_filter.values)
            clusters = linkage(sq, method="single")
            dendro_tree = to_tree(clusters, rd=False) # root node
            d3js = dict(children = [], name = "Root", length = 0)
    
            add_node(dendro_tree, d3js)
            label_tree(d3js["children"][0])
            label_leaf_node_stat(d3js["children"][0])
    
            with open("%s.json" % out_delta.replace(".txt", ""), "w") as out_js:
                json.dump(d3js, out_js, sort_keys=True, indent=4)
            jsons.append("%s.json" % out_delta.replace(".txt", ""))

    # package out into a folder for web server
    # include individual_mark + "_" + args.name + "_performance.json"
    if not args.cluster: # for cluster mode, do not output htmls
        merge_marks(jsons, args.name, args.O, args)


def from_fastq(args):
    """
    interface for snakemake
    support single end fastq files
    1. mapping with bwa
    2. macs2 to generate bdg, bdg To bigwiggle
    3. get marge2 rp and read count from bigwiggle
    4. run lisa regression to get TF enrichment
    """
    epi_database = args.histone.strip().split(",")
    fastq = os.path.abspath(args.fastq)
    sp = args.species
    prefix = args.name

    epi_new = [i for i in os.listdir(fastq) if not i.startswith('.')]
    print(epi_new)
    if set(epi_new) != set(epi_database):
        raise Exception("--histone should be the same as the input_fastq_folder")

    fastq_dict = {}
    for i in epi_new:
        path = os.path.join(fastq, i)
        fastq_dict[i] = {}
        for j in ["*fq.gz", "*.fastq.gz", "*.fastq", "*.fq"]:
            for fs in glob.glob(os.path.join(path, j)):
                fastq_dict[i][os.path.basename(fs).split('.')[0]] = fs

    config = Config(args.config, sp)
    data = dict(
        samples=fastq_dict,
        index=config.get_index)

    with open('%s.yaml' % prefix, 'w') as outfile:
        yaml.dump(data, outfile, default_flow_style=False)

    m2t = resource_filename("m2", "template")
    genome = os.path.join(m2t, "%s.genome" % sp)
    with open(resource_filename("m2", "template/Snakemake")) as t:
        t = Template(t.read())

    gene = args.gene
    output_html = args.O
    index = t.substitute({'config': "%s.yaml" % prefix,
                          'prefix': prefix,
                          "chrom": genome,
                          "bin1kb": config.genome_window,
                          'conda': resource_filename("m2", "template/conda.yaml"),
                          'originalorder': resource_filename("m2", "template/%s.1kb.bigWigAverageOverBed.originalorder.gz" % sp),
                          "sp":sp,
                          "html_out": output_html,
                          "gene": gene})

    with open(os.path.join(os.path.dirname(prefix), 'Snakefile'), 'w') as outf:
        outf.write(index)

    scripts = [resource_filename("m2", "template/lisa_merge.py"),
               resource_filename("m2", "template/lisa_h5.py")]

    os.system("cp %s ." % ' '.join(scripts))
    os.system("snakemake -j 4 --use-conda")

if __name__ == '__main__':
    main()
